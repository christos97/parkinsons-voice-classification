% Chapter 6: Results

\chapter{Results}
\label{ch:results}

\section{Overview}

This chapter presents the classification results across all experimental conditions. Results are organized by:

\begin{enumerate}
    \item \textbf{Condition-level summaries} (2$\times$2 factorial)
    \item \textbf{Model comparisons} within each condition
    \item \textbf{Feature ablation analysis} (baseline vs extended)
    \item \textbf{Class weighting analysis}
\end{enumerate}

\section{Summary of Best Results}

\subsection{Dataset A (MDVR-KCL) --- Best Performance}

\begin{table}[H]
\centering
\begin{tabular}{@{}llllp{3.5cm}@{}}
\toprule
\textbf{Metric} & \textbf{Value} & \textbf{Model} & \textbf{Task} & \textbf{Condition} \\
\midrule
ROC-AUC & $0.857 \pm 0.171$ & Random Forest & Spontaneous & Extended / Unweighted \\
Accuracy & $82.2\% \pm 16.6\%$ & Random Forest & ReadText & Extended / Unweighted \\
\bottomrule
\end{tabular}
\caption{Best performance on Dataset A}
\label{tab:best-results}
\end{table}

\subsection{Key Finding}

\begin{quote}
\textbf{Extended features (78) consistently improved performance} compared to baseline features (47). The highest ROC-AUC of \textbf{0.857} was achieved using the Extended feature set on the Spontaneous Dialogue task.
\end{quote}

\subsection{Dataset B (Benchmark)}

\begin{quote}
\textbf{Note:} Dataset B (Pre-extracted features) achieved a significantly higher ROC-AUC of $0.940 \pm 0.013$ (Random Forest). This difference is attributed to its larger sample size ($n=752$ vs $n=37$) and lack of subject-level grouping in the provided dataset, likely leading to optimistic estimates.
\end{quote}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{fig_imp_datasetb_rf.png}
    \caption{Random Forest feature importance (Dataset B). The top features are dominated by advanced signal processing metrics often unavailable in standard clinical settings.}
    \label{fig:imp-datasetb-rf}
\end{figure}

\section{Condition 1: Baseline Features + Unweighted}

\textbf{Configuration:} 47 features, no class weighting

\subsection{Task: ReadText}

\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Model} & \textbf{ROC-AUC} & \textbf{Accuracy} & \textbf{F1} \\
\midrule
Logistic Regression & $0.717 \pm 0.139$ & $0.621 \pm 0.058$ & $0.542 \pm 0.099$ \\
SVM (RBF) & $0.614 \pm 0.312$ & $0.621 \pm 0.106$ & $0.333 \pm 0.333$ \\
Random Forest & $0.590 \pm 0.302$ & $0.629 \pm 0.178$ & $0.351 \pm 0.363$ \\
\bottomrule
\end{tabular}
\caption{Condition 1 --- ReadText results}
\label{tab:c1-readtext}
\end{table}

\subsection{Task: Spontaneous Dialogue}

\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Model} & \textbf{ROC-AUC} & \textbf{Accuracy} & \textbf{F1} \\
\midrule
Logistic Regression & $0.760 \pm 0.214$ & $0.639 \pm 0.160$ & $0.539 \pm 0.321$ \\
SVM (RBF) & $0.407 \pm 0.309$ & $0.636 \pm 0.135$ & $0.400 \pm 0.253$ \\
\textbf{Random Forest} & $\mathbf{0.828 \pm 0.148}$ & $\mathbf{0.721 \pm 0.176}$ & $\mathbf{0.567 \pm 0.365}$ \\
\bottomrule
\end{tabular}
\caption{Condition 1 --- Spontaneous Dialogue results}
\label{tab:c1-spontaneous}
\end{table}

\subsection{Observations}

\begin{itemize}
    \item \textbf{Task Difference:} Spontaneous Dialogue yields significantly better separation than ReadText for Random Forest (0.828 vs 0.590) with baseline features.
    \item \textbf{Model Stability:} Logistic Regression is relatively stable across tasks (0.717--0.760).
    \item \textbf{Variance:} High standard deviations ($\pm$0.15--0.30) reflect the small sample size ($n < 40$).
\end{itemize}

\section{Condition 2: Extended Features + Unweighted}

\textbf{Configuration:} 78 features, no class weighting

\subsection{Task: ReadText}

\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Model} & \textbf{ROC-AUC} & \textbf{Accuracy} & \textbf{F1} \\
\midrule
Logistic Regression & $0.698 \pm 0.132$ & $0.596 \pm 0.079$ & $0.475 \pm 0.106$ \\
\textbf{SVM (RBF)} & $\mathbf{0.834 \pm 0.153}$ & $0.786 \pm 0.181$ & $0.634 \pm 0.386$ \\
\textbf{Random Forest} & $\mathbf{0.822 \pm 0.166}$ & $0.818 \pm 0.140$ & $0.746 \pm 0.207$ \\
\bottomrule
\end{tabular}
\caption{Condition 2 --- ReadText results}
\label{tab:c2-readtext}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{fig_imp_readtext_rf.png}
    \caption{Random Forest feature importance for ReadText task (Extended features). Fundamental frequency ($F_0$) statistics appear highly predictive.}
    \label{fig:imp-readtext-rf}
\end{figure}

\subsection{Task: Spontaneous Dialogue}

\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Model} & \textbf{ROC-AUC} & \textbf{Accuracy} & \textbf{F1} \\
\midrule
Logistic Regression & $0.783 \pm 0.139$ & $0.671 \pm 0.199$ & $0.530 \pm 0.377$ \\
SVM (RBF) & $0.460 \pm 0.294$ & $0.636 \pm 0.089$ & $0.428 \pm 0.258$ \\
\textbf{Random Forest} & $\mathbf{0.857 \pm 0.171}$ & $0.779 \pm 0.161$ & $0.605 \pm 0.387$ \\
\bottomrule
\end{tabular}
\caption{Condition 2 --- Spontaneous Dialogue results}
\label{tab:c2-spontaneous}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{fig_imp_spontaneous_rf.png}
    \caption{Random Forest feature importance for Spontaneous Dialogue task (Extended features). MFCC features show increased importance compared to ReadText.}
    \label{fig:imp-spontaneous-rf}
\end{figure}

\subsection{Observations}

\begin{itemize}
    \item \textbf{Extended Features Impact:} Massive improvement for ReadText task. Random Forest improved from 0.590 to 0.822 (+23pp), and SVM from 0.614 to 0.834 (+22pp).
    \item \textbf{Spontaneous Stability:} Spontaneous Dialogue performance improved slightly (0.828 $\rightarrow$ 0.857) but was already high.
    \item \textbf{SVM Anomaly:} SVM performs excellently on ReadText (0.834) but poorly on Spontaneous Dialogue (0.460), suggesting task-specific feature distribution effects.
\end{itemize}

\section{Feature Ablation Analysis}

\subsection{ROC-AUC Improvement from Feature Extension (ReadText)}

\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Model} & \textbf{Baseline (47)} & \textbf{Extended (78)} & \textbf{$\Delta$ ROC-AUC} \\
\midrule
Logistic Regression & 0.717 & 0.698 & $-0.019$ \\
SVM (RBF) & 0.614 & 0.834 & $\mathbf{+0.220}$ \\
Random Forest & 0.590 & 0.822 & $\mathbf{+0.232}$ \\
\bottomrule
\end{tabular}
\caption{Feature ablation --- ReadText}
\label{tab:ablation-readtext}
\end{table}

\subsection{ROC-AUC Improvement from Feature Extension (Spontaneous)}

\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Model} & \textbf{Baseline (47)} & \textbf{Extended (78)} & \textbf{$\Delta$ ROC-AUC} \\
\midrule
Logistic Regression & 0.760 & 0.783 & $+0.023$ \\
SVM (RBF) & 0.407 & 0.460 & $+0.053$ \\
Random Forest & 0.828 & 0.857 & $+0.029$ \\
\bottomrule
\end{tabular}
\caption{Feature ablation --- Spontaneous Dialogue}
\label{tab:ablation-spontaneous}
\end{table}

\textbf{Key Finding:} Feature extension was critical for the ReadText task, rescuing performance from near-chance levels (0.59) to competitive levels (0.82).

\section{Summary of Findings}

\begin{table}[H]
\centering
\begin{tabular}{@{}lcp{6cm}@{}}
\toprule
\textbf{Hypothesis} & \textbf{Result} & \textbf{Evidence} \\
\midrule
H1: Extended features improve ROC-AUC & \checkmark & +23pp on ReadText (RF) \\
H2: Spontaneous Dialogue yields better detection & \checkmark & 0.857 (Spon) vs 0.822 (Read) max \\
H3: Dataset B values are inflated & \checkmark & 0.940 (B) vs 0.857 (A) \\
H4: RF outperforms LR and SVM & \checkmark & Consistent winner across tasks \\
H5: Class weighting improves performance & $\times$ & Marginal or negative impact \\
\bottomrule
\end{tabular}
\caption{Summary of hypothesis testing}
\label{tab:hypothesis-summary}
\end{table}
