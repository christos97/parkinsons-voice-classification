% Chapter 9: Conclusion

\chapter{Conclusion}
\label{ch:conclusion}

\section{Summary of Work}

This thesis investigated voice-based classification of Parkinson's Disease (PD) versus healthy controls (HC) using classical machine learning approaches. The work addressed key methodological challenges in the field, including subject-level data leakage, class imbalance, and feature representation.

\subsection{Contributions}

\begin{enumerate}
    \item \textbf{Rigorous Evaluation Framework}
    \begin{itemize}
        \item Implemented grouped stratified cross-validation to prevent subject leakage
        \item Systematic 2$\times$2 factorial design (features $\times$ class weighting)
        \item Transparent reporting of all conditions with confidence intervals
    \end{itemize}
    
    \item \textbf{Feature Engineering Investigation}
    \begin{itemize}
        \item Extended feature set from 47 to 78 acoustic features
        \item Demonstrated +8.7 percentage point ROC-AUC improvement
        \item Identified most discriminative features ($F_0$, MFCCs, harmonicity)
    \end{itemize}
    
    \item \textbf{Class Weighting Analysis}
    \begin{itemize}
        \item Evaluated \texttt{class\_weight="balanced"} across all models
        \item Found modest effects on moderately imbalanced data
        \item Documented interaction between features and weighting
    \end{itemize}
    
    \item \textbf{Reproducible Pipeline}
    \begin{itemize}
        \item CLI-based tools for feature extraction and experiments
        \item Fixed random seeds and documented parameters
        \item Complete code repository with documentation
        \item A non-diagnostic research demonstration interface illustrating the inference workflow (Appendix~\ref{ch:demo-app})
    \end{itemize}
\end{enumerate}

\section{Key Findings}

\subsection{Primary Results}

\begin{table}[H]
\centering
\begin{tabular}{@{}lp{8cm}@{}}
\toprule
\textbf{Finding} & \textbf{Evidence} \\
\midrule
Best ROC-AUC (Dataset A): $0.857 \pm 0.171$ & Random Forest, Extended Features, SpontaneousDialogue \\
Feature extension improves RF & ReadText: +23.3pp ROC-AUC; Spontaneous: +2.9pp ROC-AUC \\
Random Forest shows robustness & Highest or competitive ROC-AUC across tasks \\
Grouped CV is essential & Prevents optimistic bias from subject leakage \\
High variance observed & Standard deviations 0.13--0.43 across metrics \\
\bottomrule
\end{tabular}
\caption{Primary research findings (Dataset A, baseline class weighting)}
\label{tab:primary-findings}
\end{table}

\subsection{Best Configuration}

\textbf{ReadText Task:}
\begin{verbatim}
Model:           Random Forest
Features:        Extended (78)
Class Weighting: None
ROC-AUC:         0.822 ± 0.166
Accuracy:        81.8% ± 14.0%
\end{verbatim}

\textbf{SpontaneousDialogue Task:}
\begin{verbatim}
Model:           Random Forest
Features:        Extended (78)
Class Weighting: None
ROC-AUC:         0.857 ± 0.171
Accuracy:        77.9% ± 16.1%
\end{verbatim}

\textbf{Note:} These results are from Dataset A (MDVR-KCL) with grouped cross-validation, representing conservative out-of-subject generalization estimates.

\subsection{Feature Importance Insights}

The most discriminative features for PD detection (Random Forest, ReadText task) include:

\begin{enumerate}
    \item \textbf{f0\_max} --- Maximum fundamental frequency (pitch ceiling)
    \item \textbf{delta\_mfcc\_2\_mean} --- Second-order MFCC temporal dynamics
    \item \textbf{f3\_std} --- Third formant variability
    \item \textbf{autocorr\_harmonicity} --- Voice quality measure (periodicity)
    \item \textbf{intensity\_mean} --- Overall vocal intensity
    \item \textbf{shimmer\_apq3} --- Amplitude perturbation (short-term)
\end{enumerate}

These align with known clinical manifestations of PD: reduced pitch range, monotone speech (low F0 variability), hypophonia (reduced intensity), and voice quality degradation (harmonicity, shimmer).

\section{Research Questions Answered}

\subsection{RQ1: How do classical ML models perform on PD voice classification?}

Classical ML achieves \textbf{ROC-AUC up to 0.857 $\pm$ 0.171} (Random Forest, extended features, SpontaneousDialogue) on Dataset A with grouped cross-validation. However, performance varies substantially:

\begin{itemize}
    \item ReadText: 0.590--0.834 ROC-AUC (baseline features, across models)
    \item SpontaneousDialogue: 0.407--0.857 ROC-AUC (baseline $\rightarrow$ extended, RF)
    \item High variance due to small sample size (n=37 subjects)
    \item Some SVM folds produced ROC-AUC $< 0.5$, indicating instability
\end{itemize}

This demonstrates the \textbf{feasibility} of voice-based PD classification, but highlights the \textbf{challenge} of robust performance on small datasets.

\subsection{RQ2: Does feature set extension improve classification performance?}

\textbf{Task-dependent.} Extending from 47 baseline to 78 extended features:

\textbf{ReadText (Random Forest):}
\begin{itemize}
    \item Baseline: 0.590 $\pm$ 0.302 ROC-AUC
    \item Extended: 0.822 $\pm$ 0.166 ROC-AUC
    \item Improvement: +23.3 percentage points (+39\% relative)
    \item Variance reduced from 0.302 to 0.166
\end{itemize}

\textbf{SpontaneousDialogue (Random Forest):}
\begin{itemize}
    \item Baseline: 0.828 $\pm$ 0.148 ROC-AUC
    \item Extended: 0.857 $\pm$ 0.171 ROC-AUC
    \item Improvement: +2.9 percentage points (modest)
\end{itemize}

The additional features capturing spectral variability (MFCC std), temporal dynamics (delta-delta MFCC), and spectral shape contributed most significantly to ReadText performance. Effects were less pronounced for SpontaneousDialogue, possibly due to higher baseline variability in spontaneous speech.

\subsection{RQ3: Does class weighting improve performance on imbalanced datasets?}

\textbf{Minimal effects observed.} On Dataset A (HC:PD ratio 1.31:1 for ReadText, 1.40:1 for SpontaneousDialogue), class weighting showed inconsistent effects:

\textbf{ReadText (Random Forest, extended features):}
\begin{itemize}
    \item Unweighted: 0.822 $\pm$ 0.166 ROC-AUC
    \item Weighted: 0.805 $\pm$ 0.182 ROC-AUC
    \item Change: -1.7pp (slight decrease)
\end{itemize}

\textbf{SpontaneousDialogue (Random Forest, baseline features):}
\begin{itemize}
    \item Unweighted: 0.828 $\pm$ 0.148 ROC-AUC
    \item Weighted: 0.827 $\pm$ 0.133 ROC-AUC
    \item Change: -0.1pp (negligible)
\end{itemize}

The moderate imbalance (1.3:1) may not be severe enough to benefit from weighting. Additionally, with only 37 subjects, class weighting may introduce additional variance. Effects varied across models and feature sets, with no consistent pattern of improvement.

\subsection{RQ4: How do results compare between grouped and standard CV?}

\textbf{Dataset A (Grouped CV, n=37 subjects):}
\begin{itemize}
    \item Random Forest: 0.590--0.857 ROC-AUC
    \item High variance (std 0.15--0.30)
    \item Subject-level generalization
\end{itemize}

\textbf{Dataset B (Standard CV, n=756 samples, subject IDs unknown):}
\begin{itemize}
    \item Random Forest: 0.940--0.949 ROC-AUC (baseline/weighted)
    \item Low variance (std 0.012--0.013)
    \item Unknown within-subject correlation
\end{itemize}

Dataset B shows substantially higher performance (+8--12pp ROC-AUC) and lower variance, consistent with potential optimistic bias from subject leakage. \textbf{Grouped CV provides more conservative but more realistic estimates} of out-of-subject generalization. The comparison is confounded by different sample sizes, feature spaces, and speech tasks, limiting direct interpretation.

\subsection{RQ5: Do speech tasks yield different classification performance?}

\textbf{Baseline features show task differences:}
\begin{itemize}
    \item ReadText: 0.590 $\pm$ 0.302 ROC-AUC (Random Forest, baseline)
    \item SpontaneousDialogue: 0.828 $\pm$ 0.148 ROC-AUC (Random Forest, baseline)
    \item Difference: +23.8pp in favor of spontaneous speech
\end{itemize}

\textbf{Extended features reduce gap:}
\begin{itemize}
    \item ReadText: 0.822 $\pm$ 0.166 (extended)
    \item SpontaneousDialogue: 0.857 $\pm$ 0.171 (extended)
    \item Difference: +3.5pp (converged)
\end{itemize}

SpontaneousDialogue may capture naturalistic PD speech characteristics (monotone prosody, reduced variability) more effectively than structured reading. However, ReadText benefits more from feature extension, possibly because extended features capture structured speech dynamics better.

\section{Implications}

\subsection{For Researchers}

\begin{itemize}
    \item \textbf{Use grouped CV} when multiple recordings per subject exist
    \item \textbf{Include variability features} (std, delta-delta) in feature sets
    \item \textbf{Report all conditions} rather than cherry-picking best results
    \item \textbf{Acknowledge limitations} transparently
\end{itemize}

\subsection{For Practitioners}

\begin{itemize}
    \item Voice-based PD screening is feasible but not yet clinical-grade
    \item Random Forest provides a robust baseline for similar tasks
    \item Feature interpretability supports clinical understanding
    \item Results require validation on independent cohorts
\end{itemize}

\subsection{For Dataset Creators}

\begin{itemize}
    \item \textbf{Always include subject identifiers} to enable proper CV
    \item Document recording conditions and equipment
    \item Provide demographic information
    \item Consider longitudinal designs
\end{itemize}

\section{Limitations Recap}

Key limitations that bound the interpretation of results:

\begin{enumerate}
    \item \textbf{Small sample size} (37 subjects) creates high variance
    \item \textbf{No hyperparameter tuning} may underestimate potential
    \item \textbf{Single dataset source} limits generalization claims
    \item \textbf{Binary classification only} --- no severity prediction
    \item \textbf{No external validation} on independent test set
\end{enumerate}

\section{Future Directions}

\subsection{Short-term Extensions}

\begin{itemize}
    \item Hyperparameter optimization with nested CV
    \item Feature selection to reduce dimensionality
    \item Multi-task fusion (ReadText + SpontaneousDialogue)
    \item Additional acoustic features (wavelets, TQWT)
\end{itemize}

\subsection{Medium-term Research}

\begin{itemize}
    \item External validation on independent datasets
    \item Deep learning with appropriate regularization
    \item Longitudinal tracking of disease progression
    \item Multi-class classification (severity levels)
\end{itemize}

\subsection{Long-term Vision}

\begin{itemize}
    \item Integration into smartphone applications
    \item Multi-modal biomarkers (voice + gait + tremor)
    \item Personalized baselines for individual tracking
    \item Clinical validation studies
\end{itemize}

\section{Closing Remarks}

This thesis demonstrates that \textbf{voice-based Parkinson's Disease classification is feasible} using classical machine learning with carefully engineered acoustic features, achieving ROC-AUC up to 0.857 on Dataset A with grouped cross-validation. The \textbf{task-dependent improvements from feature extension} (up to +23pp for ReadText) highlight the importance of capturing speech dynamics beyond simple statistical summaries.

However, the field faces significant challenges:

\begin{itemize}
    \item Small datasets (n=37) produce high variance (std 0.13--0.43)
    \item Subject identity must be tracked for valid evaluation
    \item Task selection impacts performance (structured vs spontaneous speech)
    \item Class weighting showed minimal benefit for moderate imbalance (1.3:1)
    \item Clinical deployment requires extensive validation on independent cohorts
\end{itemize}

By prioritizing \textbf{methodological validity over performance optimization}, this work provides a foundation for future research that can build toward clinically useful applications. The transparent documentation of limitations, high variance, and task-specific effects ensures that results are interpreted appropriately and that subsequent studies can address identified gaps.

\vspace{1cm}

\begin{quote}
\textit{``The goal of rigorous science is not to claim perfection, but to understand the boundaries of our knowledge.''}
\end{quote}
